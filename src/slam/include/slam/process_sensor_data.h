/**    plt::named_plot("processed lidar " + std::to_string(idx), processed_lidar_data.at(idx), "r");

 * @file process_sensor_data.h
 * @brief Header file for processing sensor data.
 * @version 0.1
 * @date 2024-06-06
 */

#ifndef PROCESS_SENSOR_DATA_H
#define PROCESS_SENSOR_DATA_H

#include <cmath>
#include <optional>
#include <vector>

typedef struct
{
    float min;
    float max;
} value_range_t;

typedef struct pose_t
{
    float x;
    float y;
    float theta;
    pose_t() : x(0), y(0), theta(0) {} // Default constructor
    pose_t(float x, float y, float theta) : x(x), y(y), theta(theta) {}
};

typedef struct
{
    float left;
    float right;
} encoder_ticks_t;

typedef struct
{
    std::size_t ray_index;
    float depth;
} obstacle_location_t;

typedef struct
{
    float x;
    float y;
} coordinate_t;

/**
 * @brief Class for processing LIDAR data.
 */
class lidar_data
{
public:
    lidar_data(
        std::size_t number_of_lidar_data_points,
        value_range_t scan_distance,
        float detection_threshold,
        const pose_t transformation_to_robot_frame,
        const float mountingAngleOffset,
        const float multiplier);

    ~lidar_data();

    [[nodiscard]] std::vector<coordinate_t> process_lidar_scan_to_robot_frame(
        std::vector<float> &lidar_scan,
        const pose_t current_pose);

    [[nodiscard]] std::vector<coordinate_t> get_coordinates_in_robot_origin_frame(
        const std::vector<coordinate_t> local_frame_coordinates,
        const pose_t current_pose);

    [[nodiscard]] std::vector<coordinate_t> transform_from_lidar_frame_to_robot_frame(
        const std::vector<coordinate_t> local_frame_coordinates);

    const std::size_t m_totalLidarDataPoints; // Total LIDAR data points

private:
    const value_range_t m_scanDistance; // LIDAR scan distance range
    const float m_detectionThreshold;   // Threshold Value to Consider an object as obstacle
    const float m_anglePerRayIncrement_Degrees;
    const pose_t m_transformation_to_robot_frame;
    const float m_mountingAngleOffset;
    const float m_multiplier;

private:
    [[nodiscard]] coordinate_t m_convert_ray_to_position(pose_t current_pose, int ray_id, float ray_value) const;

    [[nodiscard]] std::vector<float> calculate_derivative(const std::vector<float> &data) const;

    [[nodiscard]] std::vector<obstacle_location_t> find_obstacles(
        const std::vector<float> &data,
        const std::vector<float> &derivative_data) const;

    [[nodiscard]] std::vector<coordinate_t> convert_obstacle_to_coordinate_in_lidar_frame(
        const std::vector<obstacle_location_t> &obstacles,
        const pose_t currentPose) const;

    [[nodiscard]] std::vector<coordinate_t> convert_scan_to_coordinate_in_lidar_frame(const std::vector<float> &data,
                                                                                      const pose_t currentPose) const;
};

/**
 * @brief Class for robot odometry.
 */
class robot_odometry
{
public:
    robot_odometry(
        float encoder_ticks_per_mm,
        float distance_between_wheels_in_mm,
        pose_t starting_pose,
        encoder_ticks_t starting_encoder_ticks);

    robot_odometry(float distance_between_wheels_in_mm, float xStart, float yStart, float thetaStart);

    ~robot_odometry();

    [[nodiscard]] pose_t m_update_pose(encoder_ticks_t new_encoder_ticks); // Uses encoder ticks as input
    [[nodiscard]] pose_t m_update_pose(float x, float y, float theta);     // Reformats the pose in required format

private:
    const float m_encoderTicksPerMillimeter;
    const float m_robotWidthBetweenWheels_millimeters;
    encoder_ticks_t m_currentEncoderTickValue;
    pose_t m_robotPose;
    pose_t m_startPose;

private:
    void m_calculate_motion(float dL, float dR);
};

#endif // PROCESS_SENSOR_DATA_H
